{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8f5wtVEUf57"
      },
      "source": [
        "# ![image.png](data:image/png;base64,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)New Section\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAardFi4U4XX"
      },
      "source": [
        "Step 1: Load the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-tvKdFxCh9h"
      },
      "source": [
        "import pandas\n",
        "#import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXswWiEfXZIq"
      },
      "source": [
        "Step 2: Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRqFeRQUCwNv"
      },
      "source": [
        "# load dataset\n",
        "dataframe = pandas.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\", header=None)\n",
        "dataset = dataframe.values\n",
        "# In X, Input Variables are stored\n",
        "X = dataset[:,0:4].astype(float) \n",
        "# In Y, output variable is stored\n",
        "Y = dataset[:,4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajKy_Hv2De1t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06b5c988-c6fc-43e0-968b-93d6eb49d03a"
      },
      "source": [
        "dataframe.head"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of        0    1    2    3               4\n",
              "0    5.1  3.5  1.4  0.2     Iris-setosa\n",
              "1    4.9  3.0  1.4  0.2     Iris-setosa\n",
              "2    4.7  3.2  1.3  0.2     Iris-setosa\n",
              "3    4.6  3.1  1.5  0.2     Iris-setosa\n",
              "4    5.0  3.6  1.4  0.2     Iris-setosa\n",
              "..   ...  ...  ...  ...             ...\n",
              "145  6.7  3.0  5.2  2.3  Iris-virginica\n",
              "146  6.3  2.5  5.0  1.9  Iris-virginica\n",
              "147  6.5  3.0  5.2  2.0  Iris-virginica\n",
              "148  6.2  3.4  5.4  2.3  Iris-virginica\n",
              "149  5.9  3.0  5.1  1.8  Iris-virginica\n",
              "\n",
              "[150 rows x 5 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvFjbA_YaVwE"
      },
      "source": [
        "Step 3: Perform One hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ql8SfULDmW2"
      },
      "source": [
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y = np_utils.to_categorical(encoded_Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2j-ih4XYsje"
      },
      "source": [
        "print(dummy_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GelPbOovagkM"
      },
      "source": [
        "Step 4: Split the dataset into training Data and Testing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oDQFsfrIuKQ"
      },
      "source": [
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X, dummy_y , test_size=0.25, random_state=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao2Sb5BKZozp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11571acb-8716-41cd-b14b-c1f49c70a667"
      },
      "source": [
        "print(Y_validation)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUi0wWYYamkq"
      },
      "source": [
        "Step 5: Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGaozlYhDxOA"
      },
      "source": [
        "model = Sequential()\n",
        "#Input layer with 1 hidden layer\n",
        "model.add(Dense(8, input_dim=4, activation='relu'))\n",
        "#Output Layer with 3 classes\n",
        "model.add(Dense(3, activation='softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FboGO6gZbKcj"
      },
      "source": [
        "Step 6: Compile the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlXIwfxXNdSh"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZypxSxHbXXX"
      },
      "source": [
        "Step 7: Fit the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSi97gzdGpaJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61c568bb-6dad-441c-a48e-33cd5d48f28a"
      },
      "source": [
        "history=model.fit(X_train,Y_train,epochs=200, batch_size=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "23/23 [==============================] - 0s 893us/step - loss: 1.2161 - accuracy: 0.2820\n",
            "Epoch 2/200\n",
            "23/23 [==============================] - 0s 973us/step - loss: 1.0971 - accuracy: 0.3754\n",
            "Epoch 3/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 1.0141 - accuracy: 0.3239\n",
            "Epoch 4/200\n",
            "23/23 [==============================] - 0s 951us/step - loss: 0.9099 - accuracy: 0.4310\n",
            "Epoch 5/200\n",
            "23/23 [==============================] - 0s 915us/step - loss: 0.9491 - accuracy: 0.3739\n",
            "Epoch 6/200\n",
            "23/23 [==============================] - 0s 949us/step - loss: 0.9628 - accuracy: 0.3675\n",
            "Epoch 7/200\n",
            "23/23 [==============================] - 0s 893us/step - loss: 0.9349 - accuracy: 0.4534\n",
            "Epoch 8/200\n",
            "23/23 [==============================] - 0s 908us/step - loss: 0.8682 - accuracy: 0.5366\n",
            "Epoch 9/200\n",
            "23/23 [==============================] - 0s 897us/step - loss: 0.8713 - accuracy: 0.6064\n",
            "Epoch 10/200\n",
            "23/23 [==============================] - 0s 975us/step - loss: 0.8438 - accuracy: 0.5466\n",
            "Epoch 11/200\n",
            "23/23 [==============================] - 0s 877us/step - loss: 0.8473 - accuracy: 0.4995\n",
            "Epoch 12/200\n",
            "23/23 [==============================] - 0s 964us/step - loss: 0.8290 - accuracy: 0.5601\n",
            "Epoch 13/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.8438 - accuracy: 0.6204\n",
            "Epoch 14/200\n",
            "23/23 [==============================] - 0s 965us/step - loss: 0.8240 - accuracy: 0.5340\n",
            "Epoch 15/200\n",
            "23/23 [==============================] - 0s 945us/step - loss: 0.7837 - accuracy: 0.6256\n",
            "Epoch 16/200\n",
            "23/23 [==============================] - 0s 948us/step - loss: 0.7685 - accuracy: 0.6039\n",
            "Epoch 17/200\n",
            "23/23 [==============================] - 0s 956us/step - loss: 0.7619 - accuracy: 0.6245\n",
            "Epoch 18/200\n",
            "23/23 [==============================] - 0s 979us/step - loss: 0.7395 - accuracy: 0.6819\n",
            "Epoch 19/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.7086 - accuracy: 0.7344\n",
            "Epoch 20/200\n",
            "23/23 [==============================] - 0s 984us/step - loss: 0.7031 - accuracy: 0.7410\n",
            "Epoch 21/200\n",
            "23/23 [==============================] - 0s 976us/step - loss: 0.7356 - accuracy: 0.5972\n",
            "Epoch 22/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6981 - accuracy: 0.7063\n",
            "Epoch 23/200\n",
            "23/23 [==============================] - 0s 900us/step - loss: 0.6745 - accuracy: 0.7017\n",
            "Epoch 24/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6551 - accuracy: 0.7163\n",
            "Epoch 25/200\n",
            "23/23 [==============================] - 0s 922us/step - loss: 0.6360 - accuracy: 0.7260\n",
            "Epoch 26/200\n",
            "23/23 [==============================] - 0s 876us/step - loss: 0.6293 - accuracy: 0.7354\n",
            "Epoch 27/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6543 - accuracy: 0.7493\n",
            "Epoch 28/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.7400\n",
            "Epoch 29/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6141 - accuracy: 0.7263\n",
            "Epoch 30/200\n",
            "23/23 [==============================] - 0s 999us/step - loss: 0.6033 - accuracy: 0.7550\n",
            "Epoch 31/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5737 - accuracy: 0.8057\n",
            "Epoch 32/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5715 - accuracy: 0.8152\n",
            "Epoch 33/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5495 - accuracy: 0.8304\n",
            "Epoch 34/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5418 - accuracy: 0.8688\n",
            "Epoch 35/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5394 - accuracy: 0.8958\n",
            "Epoch 36/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5246 - accuracy: 0.8361\n",
            "Epoch 37/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5123 - accuracy: 0.9144\n",
            "Epoch 38/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4971 - accuracy: 0.8728\n",
            "Epoch 39/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4998 - accuracy: 0.9209\n",
            "Epoch 40/200\n",
            "23/23 [==============================] - 0s 969us/step - loss: 0.4924 - accuracy: 0.8409\n",
            "Epoch 41/200\n",
            "23/23 [==============================] - 0s 923us/step - loss: 0.4691 - accuracy: 0.8939\n",
            "Epoch 42/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4806 - accuracy: 0.9364\n",
            "Epoch 43/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4528 - accuracy: 0.9166\n",
            "Epoch 44/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4327 - accuracy: 0.9522\n",
            "Epoch 45/200\n",
            "23/23 [==============================] - 0s 909us/step - loss: 0.4556 - accuracy: 0.9303\n",
            "Epoch 46/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4490 - accuracy: 0.8897\n",
            "Epoch 47/200\n",
            "23/23 [==============================] - 0s 961us/step - loss: 0.4369 - accuracy: 0.9157\n",
            "Epoch 48/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4154 - accuracy: 0.9245\n",
            "Epoch 49/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4317 - accuracy: 0.9276\n",
            "Epoch 50/200\n",
            "23/23 [==============================] - 0s 999us/step - loss: 0.4325 - accuracy: 0.8910\n",
            "Epoch 51/200\n",
            "23/23 [==============================] - 0s 979us/step - loss: 0.4039 - accuracy: 0.9016\n",
            "Epoch 52/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4500 - accuracy: 0.9082\n",
            "Epoch 53/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4067 - accuracy: 0.9576\n",
            "Epoch 54/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3977 - accuracy: 0.9438\n",
            "Epoch 55/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3780 - accuracy: 0.9357\n",
            "Epoch 56/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4244 - accuracy: 0.9237\n",
            "Epoch 57/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3765 - accuracy: 0.9764\n",
            "Epoch 58/200\n",
            "23/23 [==============================] - 0s 941us/step - loss: 0.3800 - accuracy: 0.9311\n",
            "Epoch 59/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3839 - accuracy: 0.8868\n",
            "Epoch 60/200\n",
            "23/23 [==============================] - 0s 910us/step - loss: 0.3675 - accuracy: 0.9292\n",
            "Epoch 61/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4033 - accuracy: 0.9311\n",
            "Epoch 62/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3586 - accuracy: 0.9607\n",
            "Epoch 63/200\n",
            "23/23 [==============================] - 0s 995us/step - loss: 0.3805 - accuracy: 0.9359\n",
            "Epoch 64/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3879 - accuracy: 0.9265\n",
            "Epoch 65/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.9622\n",
            "Epoch 66/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3546 - accuracy: 0.9691\n",
            "Epoch 67/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3931 - accuracy: 0.9538\n",
            "Epoch 68/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3252 - accuracy: 0.9529\n",
            "Epoch 69/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3418 - accuracy: 0.9847\n",
            "Epoch 70/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3259 - accuracy: 0.9708\n",
            "Epoch 71/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3050 - accuracy: 0.9671\n",
            "Epoch 72/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3206 - accuracy: 0.9707\n",
            "Epoch 73/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3460 - accuracy: 0.9523\n",
            "Epoch 74/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3242 - accuracy: 0.9500\n",
            "Epoch 75/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3159 - accuracy: 0.9603\n",
            "Epoch 76/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2893 - accuracy: 0.9783\n",
            "Epoch 77/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3161 - accuracy: 0.9694\n",
            "Epoch 78/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3452 - accuracy: 0.9772\n",
            "Epoch 79/200\n",
            "23/23 [==============================] - 0s 977us/step - loss: 0.3456 - accuracy: 0.9788\n",
            "Epoch 80/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.9774\n",
            "Epoch 81/200\n",
            "23/23 [==============================] - 0s 978us/step - loss: 0.3056 - accuracy: 0.9790\n",
            "Epoch 82/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2968 - accuracy: 0.9764\n",
            "Epoch 83/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.9661\n",
            "Epoch 84/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3045 - accuracy: 0.9772\n",
            "Epoch 85/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3261 - accuracy: 0.9562\n",
            "Epoch 86/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2884 - accuracy: 0.9785\n",
            "Epoch 87/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3103 - accuracy: 0.9826\n",
            "Epoch 88/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3268 - accuracy: 0.9727\n",
            "Epoch 89/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3024 - accuracy: 0.9885\n",
            "Epoch 90/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2636 - accuracy: 0.9858\n",
            "Epoch 91/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2596 - accuracy: 0.9776\n",
            "Epoch 92/200\n",
            "23/23 [==============================] - 0s 993us/step - loss: 0.2972 - accuracy: 0.9659\n",
            "Epoch 93/200\n",
            "23/23 [==============================] - 0s 978us/step - loss: 0.2883 - accuracy: 0.9748\n",
            "Epoch 94/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2722 - accuracy: 0.9857\n",
            "Epoch 95/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3004 - accuracy: 0.9830\n",
            "Epoch 96/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3104 - accuracy: 0.9798\n",
            "Epoch 97/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2526 - accuracy: 0.9922\n",
            "Epoch 98/200\n",
            "23/23 [==============================] - 0s 932us/step - loss: 0.2606 - accuracy: 0.9678\n",
            "Epoch 99/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2517 - accuracy: 0.9847\n",
            "Epoch 100/200\n",
            "23/23 [==============================] - 0s 996us/step - loss: 0.2717 - accuracy: 0.9645\n",
            "Epoch 101/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2669 - accuracy: 0.9622\n",
            "Epoch 102/200\n",
            "23/23 [==============================] - 0s 991us/step - loss: 0.2742 - accuracy: 0.9780\n",
            "Epoch 103/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.9954\n",
            "Epoch 104/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2444 - accuracy: 0.9882\n",
            "Epoch 105/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2601 - accuracy: 0.9619\n",
            "Epoch 106/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 0.9935\n",
            "Epoch 107/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.9823\n",
            "Epoch 108/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2399 - accuracy: 0.9906\n",
            "Epoch 109/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2342 - accuracy: 0.9658\n",
            "Epoch 110/200\n",
            "23/23 [==============================] - 0s 950us/step - loss: 0.2841 - accuracy: 0.9717\n",
            "Epoch 111/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2512 - accuracy: 0.9753\n",
            "Epoch 112/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2388 - accuracy: 0.9828\n",
            "Epoch 113/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2666 - accuracy: 0.9790\n",
            "Epoch 114/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2580 - accuracy: 0.9620\n",
            "Epoch 115/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2538 - accuracy: 0.9877\n",
            "Epoch 116/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2262 - accuracy: 0.9938\n",
            "Epoch 117/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2448 - accuracy: 0.9956\n",
            "Epoch 118/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.9861\n",
            "Epoch 119/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2587 - accuracy: 0.9734\n",
            "Epoch 120/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2348 - accuracy: 0.9857\n",
            "Epoch 121/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2337 - accuracy: 0.9731\n",
            "Epoch 122/200\n",
            "23/23 [==============================] - 0s 992us/step - loss: 0.2300 - accuracy: 0.9882\n",
            "Epoch 123/200\n",
            "23/23 [==============================] - 0s 887us/step - loss: 0.2669 - accuracy: 0.9668\n",
            "Epoch 124/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1961 - accuracy: 0.9941\n",
            "Epoch 125/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2559 - accuracy: 0.9567\n",
            "Epoch 126/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2327 - accuracy: 0.9822\n",
            "Epoch 127/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2271 - accuracy: 0.9790\n",
            "Epoch 128/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2217 - accuracy: 0.9712\n",
            "Epoch 129/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2118 - accuracy: 0.9786\n",
            "Epoch 130/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.9969\n",
            "Epoch 131/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2180 - accuracy: 0.9789\n",
            "Epoch 132/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2076 - accuracy: 0.9879\n",
            "Epoch 133/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2351 - accuracy: 0.9764\n",
            "Epoch 134/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2229 - accuracy: 0.9861\n",
            "Epoch 135/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2023 - accuracy: 0.9978\n",
            "Epoch 136/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2166 - accuracy: 0.9666\n",
            "Epoch 137/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.9354\n",
            "Epoch 138/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1986 - accuracy: 0.9899\n",
            "Epoch 139/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1867 - accuracy: 0.9851\n",
            "Epoch 140/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1876 - accuracy: 0.9802\n",
            "Epoch 141/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 0.9838\n",
            "Epoch 142/200\n",
            "23/23 [==============================] - 0s 935us/step - loss: 0.2041 - accuracy: 0.9774\n",
            "Epoch 143/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1969 - accuracy: 0.9534\n",
            "Epoch 144/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1933 - accuracy: 0.9813\n",
            "Epoch 145/200\n",
            "23/23 [==============================] - 0s 948us/step - loss: 0.2031 - accuracy: 0.9870\n",
            "Epoch 146/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2071 - accuracy: 0.9837\n",
            "Epoch 147/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2055 - accuracy: 0.9843\n",
            "Epoch 148/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2103 - accuracy: 0.9766\n",
            "Epoch 149/200\n",
            "23/23 [==============================] - 0s 978us/step - loss: 0.1844 - accuracy: 0.9847\n",
            "Epoch 150/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1813 - accuracy: 0.9735\n",
            "Epoch 151/200\n",
            "23/23 [==============================] - 0s 969us/step - loss: 0.1938 - accuracy: 0.9744\n",
            "Epoch 152/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1716 - accuracy: 0.9794\n",
            "Epoch 153/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2055 - accuracy: 0.9751\n",
            "Epoch 154/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1734 - accuracy: 0.9802\n",
            "Epoch 155/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1925 - accuracy: 0.9681\n",
            "Epoch 156/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.9862\n",
            "Epoch 157/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2012 - accuracy: 0.9683\n",
            "Epoch 158/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1696 - accuracy: 0.9936\n",
            "Epoch 159/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2089 - accuracy: 0.9890\n",
            "Epoch 160/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1729 - accuracy: 0.9860\n",
            "Epoch 161/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.9504\n",
            "Epoch 162/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2031 - accuracy: 0.9528\n",
            "Epoch 163/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1903 - accuracy: 0.9774\n",
            "Epoch 164/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1632 - accuracy: 0.9765\n",
            "Epoch 165/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1739 - accuracy: 0.9673\n",
            "Epoch 166/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1778 - accuracy: 0.9767\n",
            "Epoch 167/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1654 - accuracy: 0.9826\n",
            "Epoch 168/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1573 - accuracy: 0.9617\n",
            "Epoch 169/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1775 - accuracy: 0.9756\n",
            "Epoch 170/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.9745\n",
            "Epoch 171/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1585 - accuracy: 0.9596\n",
            "Epoch 172/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1577 - accuracy: 0.9797\n",
            "Epoch 173/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1773 - accuracy: 0.9628\n",
            "Epoch 174/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1596 - accuracy: 0.9840\n",
            "Epoch 175/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.9780\n",
            "Epoch 176/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1799 - accuracy: 0.9623\n",
            "Epoch 177/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1779 - accuracy: 0.9549\n",
            "Epoch 178/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1557 - accuracy: 0.9883\n",
            "Epoch 179/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1709 - accuracy: 0.9650\n",
            "Epoch 180/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1947 - accuracy: 0.9434\n",
            "Epoch 181/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1526 - accuracy: 0.9703\n",
            "Epoch 182/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1571 - accuracy: 0.9770\n",
            "Epoch 183/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1421 - accuracy: 0.9841\n",
            "Epoch 184/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2028 - accuracy: 0.9577\n",
            "Epoch 185/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1715 - accuracy: 0.9640\n",
            "Epoch 186/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1461 - accuracy: 0.9913\n",
            "Epoch 187/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.9692\n",
            "Epoch 188/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1933 - accuracy: 0.9355\n",
            "Epoch 189/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1772 - accuracy: 0.9628\n",
            "Epoch 190/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1603 - accuracy: 0.9917\n",
            "Epoch 191/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1369 - accuracy: 0.9864\n",
            "Epoch 192/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1598 - accuracy: 0.9636\n",
            "Epoch 193/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1481 - accuracy: 0.9801\n",
            "Epoch 194/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1782 - accuracy: 0.9600\n",
            "Epoch 195/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.9785\n",
            "Epoch 196/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1312 - accuracy: 0.9941\n",
            "Epoch 197/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1455 - accuracy: 0.9772\n",
            "Epoch 198/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1285 - accuracy: 0.9836\n",
            "Epoch 199/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1570 - accuracy: 0.9810\n",
            "Epoch 200/200\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1680 - accuracy: 0.9570\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Amu1wamI-5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "202636dc-10f0-4dad-8188-ba3560e6ddbd"
      },
      "source": [
        "loss,accuracy=model.evaluate(X_train,Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1464 - accuracy: 0.9732\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qvBkA6YJ6wq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "963d0830-8ee6-482d-bbd2-51e664f621c4"
      },
      "source": [
        "print(\"Accuracy: %.2f%% Loss: %.2f%%\" % (accuracy*100,loss*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 97.32% Loss: 14.64%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4HTMXLIe8o_",
        "outputId": "fd35dab6-87c0-4551-aa7a-db3ad5153062"
      },
      "source": [
        "Actual=model.predict_classes(X_validation)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YVMX40ofPpy",
        "outputId": "89f21a98-e742-41a3-ce62-29d16266f903"
      },
      "source": [
        "for i in range(len(Y_validation)):\n",
        "\tprint(\"X=%s, Predicted=%s\" % (Y_validation[i], Actual[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X=[1. 0. 0.], Predicted=0\n",
            "X=[1. 0. 0.], Predicted=0\n",
            "X=[0. 0. 1.], Predicted=2\n",
            "X=[1. 0. 0.], Predicted=0\n",
            "X=[1. 0. 0.], Predicted=0\n",
            "X=[0. 0. 1.], Predicted=2\n",
            "X=[1. 0. 0.], Predicted=0\n",
            "X=[0. 0. 1.], Predicted=2\n",
            "X=[0. 0. 1.], Predicted=2\n",
            "X=[1. 0. 0.], Predicted=0\n",
            "X=[1. 0. 0.], Predicted=0\n",
            "X=[1. 0. 0.], Predicted=0\n",
            "X=[1. 0. 0.], Predicted=0\n",
            "X=[1. 0. 0.], Predicted=0\n",
            "X=[0. 1. 0.], Predicted=1\n",
            "X=[0. 1. 0.], Predicted=1\n",
            "X=[1. 0. 0.], Predicted=0\n",
            "X=[0. 1. 0.], Predicted=1\n",
            "X=[0. 0. 1.], Predicted=2\n",
            "X=[0. 1. 0.], Predicted=1\n",
            "X=[0. 1. 0.], Predicted=1\n",
            "X=[0. 1. 0.], Predicted=1\n",
            "X=[0. 0. 1.], Predicted=2\n",
            "X=[0. 1. 0.], Predicted=1\n",
            "X=[0. 1. 0.], Predicted=1\n",
            "X=[1. 0. 0.], Predicted=0\n",
            "X=[1. 0. 0.], Predicted=0\n",
            "X=[0. 0. 1.], Predicted=2\n",
            "X=[1. 0. 0.], Predicted=0\n",
            "X=[0. 0. 1.], Predicted=2\n",
            "X=[0. 0. 1.], Predicted=2\n",
            "X=[1. 0. 0.], Predicted=0\n",
            "X=[0. 1. 0.], Predicted=1\n",
            "X=[0. 0. 1.], Predicted=2\n",
            "X=[0. 1. 0.], Predicted=1\n",
            "X=[1. 0. 0.], Predicted=0\n",
            "X=[0. 0. 1.], Predicted=2\n",
            "X=[0. 1. 0.], Predicted=1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}